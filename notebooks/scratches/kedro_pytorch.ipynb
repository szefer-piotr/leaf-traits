{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kedro + PyTorch\n",
    "\n",
    "List Train Files: different dataset abstractions. ImageFolder used in PyTorch\n",
    "Split train validation (split based on images)\n",
    "\n",
    "`type: PartitionedDataSet\n",
    "dataset:\n",
    "type: pandas.CSVDataset\n",
    "save\n",
    "path: \"01_raw/train_images\"\n",
    "filename_suffix: \".jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Callable\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_load_func():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node that lists all train files\n",
    "def list_files(\n",
    "        partitioned_file_list: Dict[str, Callable[[], Any]], limit: int = -1\n",
    ") -> pd.DataFrame:\n",
    "    results = []\n",
    "\n",
    "    for parition_key, partition_load_func in sorted(partitioned_file_list.items()):\n",
    "        file_path = partition_load_func() #where is this \n",
    "        results.append(file_path)\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    return df if limit < 0 else df.sample(n=limit, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `datacatalog.yaml` add \n",
    "\n",
    "```\n",
    "train_images_list:\n",
    "    type: PartitionedDataSet\n",
    "    path: /data/01_raw/train_images\n",
    "    dataset: kedro_pytorch.datasets.FileWithDirAsLabel # this is a custom implementation\n",
    "    filename: \".jpg\"\n",
    "```\n",
    "\n",
    "So in the location of the pipeline there is a `datasets.py` script with implementation of that class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileWithDirAsLabel(AbstractDataSet):\n",
    "    '''Returns a dictionary of paths and labels (in my case it would be targets).\n",
    "    '''\n",
    "    def __init__(self, filepath: str):\n",
    "        self.path = filepath\n",
    "\n",
    "    def _load(self) -> dict:\n",
    "        p = Path(self.path)\n",
    "        return {'path': self.path, 'label': p.parent.name}\n",
    "\n",
    "    def _save(self, data: Any) -> None:\n",
    "        raise DataSetError(\"FileListDataset is read-only!\")\n",
    "\n",
    "    def _describe(self) -> Dict[str, Any]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NO go to the nodes in the pipeline. Another dataset created in the catalog:\n",
    "```\n",
    "train_dataset:\n",
    "    type: datasets.KedroPyTorchImageDataSet\n",
    "    path: data/train\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KedroPyTorchImageDataSet(Dataset, AbstractDataSet):\n",
    "    def __init__(\n",
    "        self,\n",
    "        path: str,\n",
    "        path_column: str = \"path\",\n",
    "        label_column: str = \"label\"\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.target_transform_fn = target_transform"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leaf-traits-1EnC7LYy-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
